{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to answer the following question. Given a tweet related to a specific topic or event, can we predict how often a tweet is retweeted based on its content?\n",
    "\n",
    "In this project, we will be focusing on the dataset that can be downloaded from:\n",
    "\n",
    "https://www.kaggle.com/rgupta09/world-cup-2018-tweets\n",
    "\n",
    "This dataset is not a part of any Kaggle competitions. It contains the tweets posted during the FIFA World Cup 2018. Our task will be to prepare the data making it suitable for machine learning algorithms and apply a classifier to predict whether a tweet was retweeted at least two times or not. In other words, if  a tweet was retweeted 0 or 1 times, it is considered non-retweeted. The reason behind choosing the threshold equal to 2 is that if a tweet is retweeted 2 or more times, it is likely to be interesting to the broad audience of Twitter users.\n",
    "\n",
    "We show here that including the hashtags of tweets in a separately vectorized form in addition to vectorizing the words of the main text of all tweets, increases the predictive accuracy of the model. We use the ExtraTreesClassifier (extremely randomized trees classifier) from scikit-learn since this algorithm is relatively fast, parallelizable and convenient when dealing with sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Loading, inspecting and extracting the relevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the garbage collection module\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FIFA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530000 entries, 0 to 529999\n",
      "Data columns (total 16 columns):\n",
      "ID                  530000 non-null int64\n",
      "lang                530000 non-null object\n",
      "Date                530000 non-null object\n",
      "Source              530000 non-null object\n",
      "len                 530000 non-null int64\n",
      "Orig_Tweet          530000 non-null object\n",
      "Tweet               529449 non-null object\n",
      "Likes               530000 non-null int64\n",
      "RTs                 530000 non-null int64\n",
      "Hashtags            468457 non-null object\n",
      "UserMentionNames    455841 non-null object\n",
      "UserMentionID       455841 non-null object\n",
      "Name                529945 non-null object\n",
      "Place               390710 non-null object\n",
      "Followers           530000 non-null int64\n",
      "Friends             530000 non-null int64\n",
      "dtypes: int64(6), object(10)\n",
      "memory usage: 64.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our dataset contains 530000 tweets of various lengths and content. The complete meanings of the columns can be found on the webpage from which the dataset was downloaded. Let's briefly reiterate what the dataset is about. First of all it contains the column 'Orig_Tweet' which is the tweet in its original form as well as the column 'Tweet' which is a cleaned tweet. The dataset also contains a tweet id 'ID', language of a tweet 'lang', date when a tweet was posted 'Date', device using which a tweet was created 'Source', the length of a tweet 'len', the number of likes 'Likes', the number of retweets 'RTs', the list of hashtags 'Hashtags', the columns with user mentioned names and user mention ids, name and place of the person who posted a tweet as well as the number of his followers and friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lang</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>len</th>\n",
       "      <th>Orig_Tweet</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>RTs</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>UserMentionNames</th>\n",
       "      <th>UserMentionID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1013597060640145408</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:45</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>140</td>\n",
       "      <td>RT @Squawka: Only two goalkeepers have saved t...</td>\n",
       "      <td>Only two goalkeepers have saved three penaltie...</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>WorldCup,POR,ENG</td>\n",
       "      <td>Squawka Football</td>\n",
       "      <td>Squawka</td>\n",
       "      <td>Cayleb</td>\n",
       "      <td>Accra</td>\n",
       "      <td>861</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013597056219295744</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:44</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>139</td>\n",
       "      <td>RT @FCBarcelona: ?? @ivanrakitic scores the wi...</td>\n",
       "      <td>scores the winning penalty to send into the qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1031</td>\n",
       "      <td>WorldCup</td>\n",
       "      <td>FC Barcelona,Ivan Rakitic,HNS | CFF</td>\n",
       "      <td>FCBarcelona,ivanrakitic,HNS_CFF</td>\n",
       "      <td>Febri Aditya</td>\n",
       "      <td>Bogor</td>\n",
       "      <td>667</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013597047482544130</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:42</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>107</td>\n",
       "      <td>RT @javierfernandez: Tonight we have big game....</td>\n",
       "      <td>Tonight we have big game</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "      <td>worldcup</td>\n",
       "      <td>Javier Fernandez,Evgeni Plushenko</td>\n",
       "      <td>javierfernandez,EvgeniPlushenko</td>\n",
       "      <td>??</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013597044198391808</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:41</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>142</td>\n",
       "      <td>We get stronger\\r\\nTurn the music up now\\r\\nWe...</td>\n",
       "      <td>We get stronger Turn the music up now We got t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PowerByEXO,WorldCup,FIFAStadiumDJ,XiuminLeague</td>\n",
       "      <td>EXO,FIFA World Cup ?</td>\n",
       "      <td>weareoneEXO,FIFAWorldCup</td>\n",
       "      <td>Frida Carrillo</td>\n",
       "      <td>Zapopan, Jalisco</td>\n",
       "      <td>17</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1013597039999926272</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:40</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>140</td>\n",
       "      <td>RT @Squawka: Only two goalkeepers have saved t...</td>\n",
       "      <td>Only two goalkeepers have saved three penaltie...</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>WorldCup,POR,ENG</td>\n",
       "      <td>Squawka Football</td>\n",
       "      <td>Squawka</td>\n",
       "      <td>tar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1013597039995867143</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:40</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>140</td>\n",
       "      <td>RT @FIFAWorldCup: \"We’re looking strong going ...</td>\n",
       "      <td>We re looking strong going into the knockout s...</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>BRAMEX</td>\n",
       "      <td>FIFA World Cup ?,CBF Futebol,Casemiro</td>\n",
       "      <td>FIFAWorldCup,CBF_Futebol,Casemiro</td>\n",
       "      <td>Ligefut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1013597039978995712</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:40</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>140</td>\n",
       "      <td>RT @ShShShShShSh555: I'm happy for #Russia win...</td>\n",
       "      <td>am happy for winning Especially since you know...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Russia</td>\n",
       "      <td>V?Deplorable?45  ??</td>\n",
       "      <td>ShShShShShSh555</td>\n",
       "      <td>?a?????</td>\n",
       "      <td>Mount Olympus</td>\n",
       "      <td>208</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1013597038951436288</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:40</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>138</td>\n",
       "      <td>RT @FridaCarrillo05: When you see me\\r\\nWhen w...</td>\n",
       "      <td>When you see me When we feel the same feeling ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PowerByEXO,WorldCup,FIFAStadiumDJ,XiuminLeague</td>\n",
       "      <td>Frida Carrillo</td>\n",
       "      <td>FridaCarrillo05</td>\n",
       "      <td>STAN LEGENDS, STAN EXO</td>\n",
       "      <td>Lima, Peru</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1013597038188154880</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:40</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>138</td>\n",
       "      <td>RT @FIFAWorldCup: Kasper Schmeichel takes the ...</td>\n",
       "      <td>Kasper Schmeichel takes the final award of the...</td>\n",
       "      <td>0</td>\n",
       "      <td>2199</td>\n",
       "      <td>ManoftheMatch,CRODEN,WorldCup</td>\n",
       "      <td>FIFA World Cup ?,Budweiser</td>\n",
       "      <td>FIFAWorldCup,Budweiser</td>\n",
       "      <td>Sky Ler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1013597037118525440</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:40</td>\n",
       "      <td>Twitter Lite</td>\n",
       "      <td>139</td>\n",
       "      <td>RT @BTSARMYNA: .@BTS_twt After 5 Years\\r\\n1. G...</td>\n",
       "      <td>After Years Global Puma Ambassador LG Mobile A...</td>\n",
       "      <td>0</td>\n",
       "      <td>5146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>???? &amp; ???? ???? ™ ??,?????</td>\n",
       "      <td>BTSARMYNA,BTS_twt</td>\n",
       "      <td>Kate</td>\n",
       "      <td>Meme City</td>\n",
       "      <td>158</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID lang                 Date               Source  len  \\\n",
       "0  1013597060640145408   en  2018-07-02 01:35:45  Twitter for Android  140   \n",
       "1  1013597056219295744   en  2018-07-02 01:35:44  Twitter for Android  139   \n",
       "2  1013597047482544130   en  2018-07-02 01:35:42  Twitter for Android  107   \n",
       "3  1013597044198391808   en  2018-07-02 01:35:41   Twitter Web Client  142   \n",
       "4  1013597039999926272   en  2018-07-02 01:35:40  Twitter for Android  140   \n",
       "5  1013597039995867143   en  2018-07-02 01:35:40  Twitter for Android  140   \n",
       "6  1013597039978995712   en  2018-07-02 01:35:40   Twitter for iPhone  140   \n",
       "7  1013597038951436288   en  2018-07-02 01:35:40   Twitter Web Client  138   \n",
       "8  1013597038188154880   en  2018-07-02 01:35:40  Twitter for Android  138   \n",
       "9  1013597037118525440   en  2018-07-02 01:35:40         Twitter Lite  139   \n",
       "\n",
       "                                          Orig_Tweet  \\\n",
       "0  RT @Squawka: Only two goalkeepers have saved t...   \n",
       "1  RT @FCBarcelona: ?? @ivanrakitic scores the wi...   \n",
       "2  RT @javierfernandez: Tonight we have big game....   \n",
       "3  We get stronger\\r\\nTurn the music up now\\r\\nWe...   \n",
       "4  RT @Squawka: Only two goalkeepers have saved t...   \n",
       "5  RT @FIFAWorldCup: \"We’re looking strong going ...   \n",
       "6  RT @ShShShShShSh555: I'm happy for #Russia win...   \n",
       "7  RT @FridaCarrillo05: When you see me\\r\\nWhen w...   \n",
       "8  RT @FIFAWorldCup: Kasper Schmeichel takes the ...   \n",
       "9  RT @BTSARMYNA: .@BTS_twt After 5 Years\\r\\n1. G...   \n",
       "\n",
       "                                               Tweet  Likes   RTs  \\\n",
       "0  Only two goalkeepers have saved three penaltie...      0   477   \n",
       "1  scores the winning penalty to send into the qu...      0  1031   \n",
       "2                           Tonight we have big game      0   488   \n",
       "3  We get stronger Turn the music up now We got t...      0     0   \n",
       "4  Only two goalkeepers have saved three penaltie...      0   477   \n",
       "5  We re looking strong going into the knockout s...      0   153   \n",
       "6  am happy for winning Especially since you know...      0     4   \n",
       "7  When you see me When we feel the same feeling ...      0     1   \n",
       "8  Kasper Schmeichel takes the final award of the...      0  2199   \n",
       "9  After Years Global Puma Ambassador LG Mobile A...      0  5146   \n",
       "\n",
       "                                         Hashtags  \\\n",
       "0                                WorldCup,POR,ENG   \n",
       "1                                        WorldCup   \n",
       "2                                        worldcup   \n",
       "3  PowerByEXO,WorldCup,FIFAStadiumDJ,XiuminLeague   \n",
       "4                                WorldCup,POR,ENG   \n",
       "5                                          BRAMEX   \n",
       "6                                          Russia   \n",
       "7  PowerByEXO,WorldCup,FIFAStadiumDJ,XiuminLeague   \n",
       "8                   ManoftheMatch,CRODEN,WorldCup   \n",
       "9                                             NaN   \n",
       "\n",
       "                        UserMentionNames                      UserMentionID  \\\n",
       "0                       Squawka Football                            Squawka   \n",
       "1    FC Barcelona,Ivan Rakitic,HNS | CFF    FCBarcelona,ivanrakitic,HNS_CFF   \n",
       "2      Javier Fernandez,Evgeni Plushenko    javierfernandez,EvgeniPlushenko   \n",
       "3                   EXO,FIFA World Cup ?           weareoneEXO,FIFAWorldCup   \n",
       "4                       Squawka Football                            Squawka   \n",
       "5  FIFA World Cup ?,CBF Futebol,Casemiro  FIFAWorldCup,CBF_Futebol,Casemiro   \n",
       "6                    V?Deplorable?45  ??                    ShShShShShSh555   \n",
       "7                         Frida Carrillo                    FridaCarrillo05   \n",
       "8             FIFA World Cup ?,Budweiser             FIFAWorldCup,Budweiser   \n",
       "9            ???? & ???? ???? ™ ??,?????                  BTSARMYNA,BTS_twt   \n",
       "\n",
       "                     Name             Place  Followers  Friends  \n",
       "0                  Cayleb             Accra        861      828  \n",
       "1            Febri Aditya             Bogor        667      686  \n",
       "2                      ??               NaN         65       67  \n",
       "3          Frida Carrillo  Zapopan, Jalisco         17       89  \n",
       "4                     tar               NaN        137      216  \n",
       "5                 Ligefut               NaN         29      283  \n",
       "6                 ?a?????    Mount Olympus         208      338  \n",
       "7  STAN LEGENDS, STAN EXO        Lima, Peru          7        9  \n",
       "8                 Sky Ler               NaN          1        6  \n",
       "9                    Kate        Meme City         158      245  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all the tweets are in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    530000\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of predictive modeling, we remove the 'ID', 'Date', 'Name', 'Place', 'UserMentionNames', 'UserMentionID' as well as 'lang' column given that all the tweets are in English. We will also remove the 'Source' (using which a retweet was made) column as a feature that is not relevant for the textual data. In other words, we remove everything that is related to a user rather than the tweets' content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530000 entries, 0 to 529999\n",
      "Data columns (total 8 columns):\n",
      "len           530000 non-null int64\n",
      "Orig_Tweet    530000 non-null object\n",
      "Tweet         529449 non-null object\n",
      "Likes         530000 non-null int64\n",
      "RTs           530000 non-null int64\n",
      "Hashtags      468457 non-null object\n",
      "Followers     530000 non-null int64\n",
      "Friends       530000 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 32.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['ID', 'Date', 'Name', 'Place','UserMentionID', 'UserMentionNames',\n",
    "         'lang', 'Source'], axis =1, inplace = True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the correlation between numerical columns, we see that the number of retweets 'RTs' is almost uncorrelated with other numerical columns. It is interesting to note that the number of likes is somewhat correlated with the number of followers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>Likes</th>\n",
       "      <th>RTs</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.060993</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.024858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Likes</th>\n",
       "      <td>0.002834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.237121</td>\n",
       "      <td>0.012415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTs</th>\n",
       "      <td>0.060993</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.020850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Followers</th>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.237121</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friends</th>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.012415</td>\n",
       "      <td>-0.020850</td>\n",
       "      <td>0.037608</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len     Likes       RTs  Followers   Friends\n",
       "len        1.000000  0.002834  0.060993   0.012815  0.024858\n",
       "Likes      0.002834  1.000000 -0.004365   0.237121  0.012415\n",
       "RTs        0.060993 -0.004365  1.000000  -0.011836 -0.020850\n",
       "Followers  0.012815  0.237121 -0.011836   1.000000  0.037608\n",
       "Friends    0.024858  0.012415 -0.020850   0.037608  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the 'len', 'Likes', 'Followers' and 'Friends' columns as well not only because they are uninformative, but also because they do not serve the main purpose of the task which is to make a prediction based of the text of a tweet and relevant hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530000 entries, 0 to 529999\n",
      "Data columns (total 4 columns):\n",
      "Orig_Tweet    530000 non-null object\n",
      "Tweet         529449 non-null object\n",
      "RTs           530000 non-null int64\n",
      "Hashtags      468457 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 16.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['len', 'Likes', 'Followers', 'Friends'], axis =1, inplace = True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we see that after cleaning the original tweets according to the rules of the databese provider, some cleaned tweets became empty. Our purpose is to do our own text cleaning and  preprocessing. Thus we drop the 'Tweet' column that contains the cleaned tweets. Quite many tweets do not contain any hashtags, and this is absolutely normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530000 entries, 0 to 529999\n",
      "Data columns (total 3 columns):\n",
      "Orig_Tweet    530000 non-null object\n",
      "RTs           530000 non-null int64\n",
      "Hashtags      468457 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Tweet'], axis =1, inplace = True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Tweet</th>\n",
       "      <th>RTs</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @BTSARMYNA: .@BTS_twt After 5 Years\\r\\n1. G...</td>\n",
       "      <td>5146</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT @IanStaffs: Just worked out that if England...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @CCFCFan1927: People getting rightly excite...</td>\n",
       "      <td>6889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT @Onyema_Donald: ?? Edinson Cavani for Napol...</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RT @FIFAWorldCup: ?? | \"Japan have never made ...</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529964</th>\n",
       "      <td>RT @NOTSportsCenter: BREAKING: The Golden Stat...</td>\n",
       "      <td>848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529966</th>\n",
       "      <td>RT @FEMENSWE: PUSSY RIOT\\r\\n1.    Let all poli...</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529968</th>\n",
       "      <td>RT @K_SUPREME_ZA: Please guys please please he...</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529970</th>\n",
       "      <td>RT @FourFourTweet: According to various report...</td>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529985</th>\n",
       "      <td>RT @Sporf: ? Ronaldo's Hattrick\\r\\n\\r\\n?? Germ...</td>\n",
       "      <td>1138</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61543 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Orig_Tweet   RTs Hashtags\n",
       "9       RT @BTSARMYNA: .@BTS_twt After 5 Years\\r\\n1. G...  5146      NaN\n",
       "14      RT @IanStaffs: Just worked out that if England...     7      NaN\n",
       "15      RT @CCFCFan1927: People getting rightly excite...  6889      NaN\n",
       "17      RT @Onyema_Donald: ?? Edinson Cavani for Napol...    70      NaN\n",
       "18      RT @FIFAWorldCup: ?? | \"Japan have never made ...   219      NaN\n",
       "...                                                   ...   ...      ...\n",
       "529964  RT @NOTSportsCenter: BREAKING: The Golden Stat...   848      NaN\n",
       "529966  RT @FEMENSWE: PUSSY RIOT\\r\\n1.    Let all poli...     9      NaN\n",
       "529968  RT @K_SUPREME_ZA: Please guys please please he...    87      NaN\n",
       "529970  RT @FourFourTweet: According to various report...  1308      NaN\n",
       "529985  RT @Sporf: ? Ronaldo's Hattrick\\r\\n\\r\\n?? Germ...  1138      NaN\n",
       "\n",
       "[61543 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Hashtags'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis and further preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we substitute the absent hashtags with the word 'nohashtags'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hashtags'] = df['Hashtags'].fillna('nohashtags')\n",
    "\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we notice that are only 133390 unique original tweets, and 37140 unique combinations of hashtags. This means that the same tweet may have been retweeted many times from different places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Orig_Tweet    133390\n",
       "Hashtags       37140\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Orig_Tweet', 'Hashtags']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will group by the unique combinations of original tweets and hashtags and average over all the numbers of retweets. This is to ensure that the retweet by a given user is counted exactly once.\n",
    "After that, we are left with 133390 unique entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Tweet</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>RTs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! BIG FINAL !!!\\r\\nFIFA WORLD CUP RUSSIA 201...</td>\n",
       "      <td>fifaworldcup2018,FRNvsCRO,france,vs,croatia,fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!! Give away time !!!!\\r\\nWe are giving away ...</td>\n",
       "      <td>irishgnt,russells,oldcarrickmill,Competition,g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!#WorldCup Pre-Match TIP!!\\r\\n(A Penalty in t...</td>\n",
       "      <td>WorldCup,Bet,Football,Tip,BEL,FRA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!#WorldCup TIP!! @bet365 #BetBuilder\\r\\n(Over...</td>\n",
       "      <td>WorldCup,BetBuilder,Bet,Football,Tip,FRA,BEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!![##LIVE STREAM##]#+=&amp;gt; France vs,. Belgium...</td>\n",
       "      <td>LIVE,WorldCup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Orig_Tweet  \\\n",
       "0  !!! BIG FINAL !!!\\r\\nFIFA WORLD CUP RUSSIA 201...   \n",
       "1  !!! Give away time !!!!\\r\\nWe are giving away ...   \n",
       "2  !!#WorldCup Pre-Match TIP!!\\r\\n(A Penalty in t...   \n",
       "3  !!#WorldCup TIP!! @bet365 #BetBuilder\\r\\n(Over...   \n",
       "4  !![##LIVE STREAM##]#+=&gt; France vs,. Belgium...   \n",
       "\n",
       "                                            Hashtags  RTs  \n",
       "0  fifaworldcup2018,FRNvsCRO,france,vs,croatia,fi...    0  \n",
       "1  irishgnt,russells,oldcarrickmill,Competition,g...    1  \n",
       "2                  WorldCup,Bet,Football,Tip,BEL,FRA    0  \n",
       "3       WorldCup,BetBuilder,Bet,Football,Tip,FRA,BEL    0  \n",
       "4                                      LIVE,WorldCup    0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby(['Orig_Tweet', 'Hashtags']).mean().reset_index()\n",
    "\n",
    "df['RTs'] = df['RTs'].astype(np.int64)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 133390 entries, 0 to 133389\n",
      "Data columns (total 3 columns):\n",
      "Orig_Tweet    133390 non-null object\n",
      "Hashtags      133390 non-null object\n",
      "RTs           133390 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of retweets are broadly distributed (with a peak around zero) although this distribution is highly non-uniform. The absolute majority of tweets have zero and small number of retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>133390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.300532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>509.367267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58182.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RTs\n",
       "count  133390.000000\n",
       "mean       38.300532\n",
       "std       509.367267\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         2.000000\n",
       "max     58182.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['RTs'].plot.hist(bins=50, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very few tweets resulted in large number of retweets as one can see from below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5546 tweets have the number of retweets greater than 100.\n",
      "1657 tweets have the number of retweets greater than 500.\n",
      "878 tweets have the number of retweets greater than 1000.\n",
      "142 tweets have the number of retweets greater than 5000.\n",
      "59 tweets have the number of retweets greater than 10000.\n"
     ]
    }
   ],
   "source": [
    "for i in [100, 500, 1000, 5000, 10000]:\n",
    "    print('{} tweets have the number of retweets greater than {}.'\\\n",
    "          .format(len(df[df.RTs >i].index), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, 58 percent of tweets were never retweeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of tweets that were never retweeted is: 0.5852537671489617\n"
     ]
    }
   ],
   "source": [
    "print('The fraction of tweets that were never retweeted is:',\n",
    "     df.loc[df.RTs == 0]['RTs'].count()/len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a new column 'Retweeted?' that has the values 0 and 1. 0 corresponds to a tweet that was retweeted 0 or 1 times, and 1 describes the situation when a tweet was retweeted at least twice. We see that our dataset becomes highly imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Retweeted?'] = df['RTs'].map(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "df['Retweeted?'] = df['RTs'].map(lambda x: 0 if x <= 1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    95670\n",
       "1    37720\n",
       "Name: Retweeted?, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Retweeted?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now proceed to preparing the text suitable machine learning algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) We first remove RT signs, urls, hashtags, user mentions, \\n, \\r form the tweets. We also  remove spaces from the sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean1(tw):\n",
    "    \n",
    "    #remove hashtags\n",
    "    x = re.sub(r'#\\S+', '', tw)\n",
    "    \n",
    "    #remove user-mentions\n",
    "    x = re.sub(r'@\\S+', '', x)\n",
    "    \n",
    "    #remove urls\n",
    "    x = re.sub(r'http\\S+', '', x)\n",
    "    x = re.sub(r'ftp\\S+', '', x)\n",
    "    \n",
    "    # remove \\n and \\r\n",
    "    x = re.sub(r'\\r|\\n', '', x)\n",
    "    \n",
    "    #remove RT signs\n",
    "    x = re.sub(r'RT', '', x)\n",
    "    x = re.sub(r'&amp', '', x)\n",
    "    \n",
    "    #remove spaces from the sides\n",
    "    x = x.strip()\n",
    "    \n",
    "    return x\n",
    "    \n",
    "df['Orig_Tweet'] = df['Orig_Tweet'].map(clean1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Then, we will substitute the contractions with more readable expressions (I'll -> I will etc). This is not perfect, because for example 'I'd' can be interpreted as 'I had' and 'I would' depending on the tense. It is not a problem because the auxiliary verbs will be removed later anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(tw):\n",
    "    \n",
    "    #substitute the type of apostrophe\n",
    "    x = re.sub(r'\\’', '\\'', tw)\n",
    "    \n",
    "    x = re.sub(r'won\\'t', 'will not', x)\n",
    "    x = re.sub(r'can\\'t', 'can not', x)\n",
    "    x = re.sub(r'n\\'t', ' not', x)\n",
    "    x = re.sub(r'\\'re', ' are', x)\n",
    "    x = re.sub(r'\\'s', ' is', x)\n",
    "    x = re.sub(r'\\'d', ' would', x)\n",
    "    x = re.sub(r'\\'ll', ' will', x)\n",
    "    x = re.sub(r'\\'t', ' not', x)\n",
    "    x = re.sub(r'\\'ve', ' have', x)\n",
    "    x = re.sub(r'\\'m', ' am', x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "df['Orig_Tweet'] = df['Orig_Tweet'].map(decontracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Orig_Tweet'].tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) After that, we remove punctuation as well as digits, duplicate spaces inside the tweets and make everything lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean2(tw):\n",
    "    \n",
    "    #remove punctuation and digits\n",
    "    x = re.sub(r'[^a-zA-Z]+', ' ', tw)\n",
    "    \n",
    "    #remove duplicate spaces\n",
    "    x = re.sub('\\s{2,}', ' ', x)\n",
    "    \n",
    "    #make lowecase\n",
    "    x = x.lower()\n",
    "    \n",
    "    #remove spaces from the sides\n",
    "    x = x.strip()\n",
    "    \n",
    "    return x\n",
    " \n",
    "df['Orig_Tweet'] = df['Orig_Tweet'].map(clean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Orig_Tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create our own list of stopwords. Not all stopwords privided by nltk should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    " \n",
    "from nltk.corpus import stopwords   \n",
    "#print(list(set(stopwords.words('english'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " not_stopwords =['now', 'both', 'before', 'below', 'above','some',\n",
    "               'most', 'through', 'other', 'through', 'such', 'only',\n",
    "                 'over', 'during', 'against', 'again', 'under', 'few',\n",
    "                 'after', 'between', 'further', 'very', 'once', 'more',\n",
    "                'no', 'not', 'nor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = list(set(stopwords.words('english')) - set(not_stopwords))\n",
    "\n",
    "#print(my_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also rename the column 'Orig_Tweet' back to 'Tweet'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column 'Orig_Tweet' back  to 'Tweet'\n",
    "df = df.rename(columns={\"Orig_Tweet\": \"Tweet\"}, copy = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final preprocessing step, we will make all the hashtags lowercase, and add back the hashtag sign '#' to distinguish the hashtags form the usual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all hashtags lowercase \n",
    "df['Hashtags'] = df['Hashtags'].map(lambda x: x.lower())\n",
    "\n",
    "#df['Hashtags'].iloc[6785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'Hashtags' column contains the text of comma-separated hashtags;\n",
    "# so we first split the text and then add '#' to each element separately.\n",
    "\n",
    "def add_hashtag_sign(x):\n",
    "    \n",
    "    y = x.split(',')\n",
    "    for i in range(len(y)):\n",
    "        y[i]= '#'+y[i]\n",
    "    \n",
    "    return ','.join(y)\n",
    "\n",
    "df['Hashtags'] = df['Hashtags'].map(add_hashtag_sign)\n",
    "\n",
    "#df['Hashtags'].iloc[6785]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicitve Modelling I (text without hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will use TfidfVectorizer along with ExtraTreesClassifier to perform the GridSearch crossvalidation to determine the minimum document frequency giving the best accuracy. There is no sense to tune other parameters such as maximum document frequency and maximum number of features because tweets are short and diverse.\n",
    "\n",
    "The procedure will be performed based only on the 'Tweet' column containing the text of a tweet without hashtags. Because of the size of the dataset, we use only 3-fold cross-validation and 20 estimators in our tree-based classifier. TfidfVectorizer will be applied to uni-grams and bi-grams meaning that ngram_range = (1,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary classes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataframe\n",
    "\n",
    "df = df.sample(frac=1, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the train-test split\n",
    "\n",
    "X, y = df['Tweet'], df['Retweeted?']\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(X, y, test_size=0.25, stratify = y, random_state= 53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying the TfidfVectorizer to the text of a tweet, we use the PorterStemmer to stem the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()\\\n",
    "            if word not in my_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best patameters: {'tfidf__min_df': 1}\n",
      "The best cross-validation accuracy: 0.7617100882125194\n",
      "Test accuracy score: 0.7821158690176322\n",
      "Wall time: 1h 30min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#apply the TfidfVectorizer to the stemmed test of the 'Tweet'\n",
    "tfidf = TfidfVectorizer(stop_words=my_stopwords, \n",
    "                                   ngram_range=(1, 2),\n",
    "                                  tokenizer = tokenizer_porter)\n",
    "\n",
    "#initiate ExtraTreesClassifier with 20 estimators\n",
    "extclass = ExtraTreesClassifier(n_estimators=20, \n",
    "                             max_depth = None, \n",
    "                             max_features = 'auto', bootstrap = False,  \n",
    "                             n_jobs = -1, random_state = 987)\n",
    "\n",
    "#make the pipeline\n",
    "pipe = Pipeline([('tfidf', tfidf), ('extclass', extclass)])\n",
    "\n",
    "#we search the minimum document frequency amon values 1,2 and 3\n",
    "param_grid = {'tfidf__min_df':[1,2,3]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid = param_grid, cv =3, n_jobs =-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best patameters:', grid.best_params_)\n",
    "\n",
    "print('The best cross-validation accuracy:', grid.best_score_)\n",
    "\n",
    "print('Test accuracy score:', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the test accuracy score is about 0.78 which is not very high, albeit we used only 20 estimators. Higher number of estimators is expected to increase this score only slightly. We see also that the optimal document frequency is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, X_test, y_train, y_test, X, y, tfidf, extclass, pipe\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicitve Modelling II (text and hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we do the predictive modeling keeping both the 'Tweet' column that contains the words of the main text, and the 'Hashtags column'. Applying TfidfVectorizers to both columns we use min_df=1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the train-test split\n",
    "\n",
    "X1, X2, y = df['Hashtags'], df['Tweet'], df['Retweeted?']\n",
    "\n",
    "X1_train, X1_test, X2_train, X2_test, y_train, y_test =\\\n",
    "train_test_split(X1, X2, y,test_size=0.25, stratify = y, random_state= 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100042x52472 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 404374 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply TfidfVectorizer to 'Hashtags'\n",
    "\n",
    "tfidf_vectorizer1 = TfidfVectorizer(stop_words=None, \n",
    "                                    min_df = 1,\n",
    "                                   ngram_range=(1, 2),\n",
    "                                  tokenizer = None)\n",
    "\n",
    "tfidf_train1 = tfidf_vectorizer1.fit_transform(X1_train.values)\n",
    "\n",
    "tfidf_train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying the TfidfVectorizer to the 'Tweet' column, we use the PorterStemmer to stem the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()\\\n",
    "            if word not in my_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100042x332543 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1474988 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply the TfidfVectorizer to the stemmed test of the 'Tweet'\n",
    "\n",
    "tfidf_vectorizer2 = TfidfVectorizer(stop_words=my_stopwords, \n",
    "                                   ngram_range=(1, 2), min_df =1,\n",
    "                                  tokenizer = tokenizer_porter)\n",
    "\n",
    "tfidf_train2 = tfidf_vectorizer2.fit_transform(X2_train.values)\n",
    "\n",
    "tfidf_train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then transform the X1_test and X2_test using the corresponding TfidfVecorizers and concatenate horizontally two pairs of sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test1 = tfidf_vectorizer1.transform(X1_test.values)\n",
    "tfidf_test2 = tfidf_vectorizer2.transform(X2_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "tfidf_train = hstack([tfidf_train2, tfidf_train1])\n",
    "tfidf_test = hstack([tfidf_test2, tfidf_test1])\n",
    "\n",
    "#tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100042x385015 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1879362 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the ExtraTreesClassifier to do the predictive modeling using as many as 100 estimators (this is in fact the default value). Given the size of the dataset, it takes a long time to complete the training on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 0.9868755122848404\n",
      "Test accuracy score: 0.8087141657670625\n",
      "Wall time: 2h 8min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "extclass = ExtraTreesClassifier(n_estimators=100, \n",
    "                             max_depth = None, \n",
    "                             max_features = 'auto', bootstrap = False,  \n",
    "                             n_jobs = -1, random_state = 987)\n",
    "\n",
    "extclass.fit(tfidf_train, y_train)\n",
    "\n",
    "y_train_pred = extclass.predict(tfidf_train)\n",
    "y_test_pred = extclass.predict(tfidf_test)\n",
    "\n",
    "print('Train accuracy score:', accuracy_score(y_train_pred, y_train))\n",
    "print('Test accuracy score:', accuracy_score(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that vectorizing the lists of hashtags and concatenating the corresponding matrix with the matrix of vectorized words of the main text, helped to raise the accuracy on the test set to 0.81. Plotting the confusion matrix we see that the main error comes from the fact that too many retweeted twits were incorrectly predicted as not retweeted. If not retweeted tweets are labeled as negative and retweeted as positive, we are dealing with the problem of large number of false negatives. This problem is not uncommon for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "disp = plot_confusion_matrix(extclass, tfidf_test, y_test,\n",
    "                                 display_labels=['Not retweeted', 'Retweeted'],\n",
    "                                 normalize = 'all', cmap = 'plasma')\n",
    "\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, we addressed the following classification and natural language processing problem: Can we predict whether a tweet is retweeted at least twice based on its content. We made all the text preprocessing from scratch followed by Tf-idf vectorization, and used ExtraTrees Classifier to do the predictive modeling. We showed that better results can be obtained if the hashtags that may be present in a tweet are vectorized separately and added to the vectorized words of the main text.\n",
    "The accuracy on the test set achieved as a result of training is about 0.81. This is not very high but probably reasonable given the fact we deal with very short and diverse samples of the text. To achieve higher accuracy, one needs to think how one can reduce the number of false negatives as a result of making predictions. For the future, one can try to address the same problem with the help of deep learning, albeit training the neural networks of deep architecture may be prohibitive given the size of the dataset and absence of GPU.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
